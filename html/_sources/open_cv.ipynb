{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Traitement d'images avec OpenCv </center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installer la bibliothèque opencv\n",
    "\n",
    "\n",
    "commande: pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importer la bibliothèque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lire une image et afficher son type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"messi.jpg\")\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Afficher cette image et sa taille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 1200, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('Original Image', img) \n",
    "cv2.waitKey(0)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rotation de l'image\n",
    "\n",
    "Pour faire la rottation cette image, vous avez besoin de sa largeur et sa hauteur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Récuperation de la largeur et la hauteur\n",
    "height, width = img.shape[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour obtenir la matrice de rotation, nous utilisons la méthode getRotationMatrix2D () de cv2. Pour faire la rotation, nous avons une méthode wrapAffine de cv2 qui prend l'image d'origine, la matrice de rotation de l'image et la largeur et la hauteur de l'image comme arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 1200, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Faire la rotation et l'affichage\n",
    "\n",
    "rotationMatrix = cv2.getRotationMatrix2D((width/2, height/2), 90, .5)\n",
    "rotatedImage = cv2.warpAffine(img, rotationMatrix, (width, height))\n",
    "print(rotatedImage.shape)\n",
    "cv2.imshow('Rotated Image', rotatedImage)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recadrer une image\n",
    "\n",
    "Récupérez l'index de début et de fin de la ligne et de la colonne. Cela définira la taille de l'image nouvellement créée. Par exemple, commencer de la ligne numéro 10 jusqu'à la ligne numéro 15 donnera la hauteur de l'image. De même, commencez à partir de la colonne numéro 10 jusqu'à ce que la colonne numéro 15 donne la largeur de l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startRow = int(height*.05)\n",
    "\n",
    "startCol = int(width*.25)\n",
    "\n",
    "endRow = int(height*.65)\n",
    "\n",
    "endCol = int(width*.65)\n",
    "\n",
    "croppedImage = img[startRow:endRow, startCol:endCol]\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "\n",
    "cv2.imshow('Cropped Image', croppedImage)\n",
    "cv2.imwrite(\"Cropped_Image.png\",croppedImage)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Redimensionner une image\n",
    "\n",
    "Pour redimensionner une image, vous pouvez utiliser la méthode resize() d'openCV. Dans cette méthode, vous pouvez spécifier les valeurs des axes x et y ou le nombre de lignes et de colonnes qui indique la taille de l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newImg = cv2.resize(img, (550, 350))\n",
    "\n",
    "cv2.imshow('Resized Image', newImg)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ajuster le contraste de l'image\n",
    "\n",
    "Dans le module OpenCV, il n'y a pas de fonction particulière pour ajuster le contraste de l'image mais la documentation officielle d'OpenCV suggère une équation qui peut ajuster la luminosité de l'image et le contraste de l'image à la fois:\n",
    "\n",
    "Image= a*Image + b\n",
    "\n",
    "Avec a qui définit le contraste de l'image. Si a est supérieur à 1, le contraste sera plus élevé. Si la valeur de a est comprise entre 0 et 1 (inférieure à 1 mais supérieure à 0), le contraste serait plus faible. Si a vaut 1, il n'y aura aucun effet de contraste sur l'image.\n",
    "\n",
    "b un paramètre d'ajustement qui varie de -127 à +127.\n",
    "\n",
    "Utilisez la fonction addWeighted() pour faire cette transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "contrast_img = cv2.addWeighted(img, 2.5, np.zeros(img.shape, img.dtype), 0, 0)\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "\n",
    "cv2.imshow('Contrast Image', contrast_img)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Rendre une image floue\n",
    "\n",
    "Pour rendre une image floue, utiliser les deux méthodes GaussianBlur() et medianBlur() de opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avec GaussianBlur()\n",
    "\n",
    "blur_image = cv2.GaussianBlur(img, (7,7), 0)\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "\n",
    "cv2.imshow('Blur Image', blur_image)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avec medianBlur()\n",
    "\n",
    "blur_image = cv2.medianBlur(img,5)\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "\n",
    "cv2.imshow('Blur Image', blur_image)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Detecter les contours\n",
    "\n",
    "Pour détecter les contours dans une image, vous pouvez utiliser la méthode Canny () de cv2 qui implémente le détecteur de bord Canny. Le détecteur de bord Canny est également connu comme le détecteur le plus optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_img = cv2.Canny(img,100,200)\n",
    "\n",
    "cv2.imshow(\"Detected Edges\", edge_img)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Convertir une image en niveau de gris\n",
    "\n",
    "Essayer de convertir une image en niveau de gris en utilisant les deux méthodes:  avec la méthode imread() et avec la méthode cvtColor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img= cv2.imread(\"test.png\")\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "\n",
    "cv2.imshow(\"Gray Scale Image\", gray_img)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Les canneaux Rouge, Vert, Bleu\n",
    "\n",
    "Récuperer les canneaux rouge, Vert et bleu de l'image originale et affichez les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue, green, red = cv2.split(img) # Split the image into its channels\n",
    "cv2.imshow(\"Red Channel\",red) # Display the red channel in the image\n",
    "cv2.imshow(\"Blue Channel\",blue) # Display the red channel in the image\n",
    "cv2.imshow(\"Green Channel\",green) # Display the red channel in the image\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Détection du centre de gravité de l'image\n",
    "\n",
    "Pour trouver le centre d'une image, la première étape consiste à convertir l'image d'origine en niveaux de gris. Calculer les moments de l'image. Utilisez la méthode moments () de cv2. Ensuite, nous devons calculer les coordonnées x et y du centre de l'image en utilisant les moments que nous avons obtenus. Dessinez un cercle sur ce centre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moment = cv2.moments(gray_img)\n",
    "moment\n",
    "\n",
    "X = int(moment [\"m10\"] / moment[\"m00\"])\n",
    "\n",
    "Y = int(moment [\"m01\"] / moment[\"m00\"])\n",
    "\n",
    "cv2.circle(img, (X, Y), 15, (205, 114, 101),1)\n",
    "\n",
    "cv2.imshow(\"Center of the Image\", img)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Extraction de texte à partir d'une image (OCR)\n",
    "\n",
    "Pour extraire du texte à partir d'une image, vous pouvez utiliser Google Tesseract-OCR. Vous pouvez le télécharger à partir de ce lien: https://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-3.05.02-20180621.exe\n",
    "\n",
    "Ensuite, vous devez installer le module pytesseract sur Anaconda qui est un wrapper Python pour Tesseract-OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import os\n",
    "os.environ['TESSDATA_PREFIX']='C:\\Program Files (x86)\\Tesseract-OCR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was the best of\n",
      "times, it was the worst\n",
      "of times, it was the age\n",
      "of wisdom, it was the\n",
      "age of foolishness...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pytesseract.image_to_string('text.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Réduire le bruit pour une image couleur et en niveau de gris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread(\"lenna.png\")\n",
    "result = cv2.fastNlMeansDenoisingColored(img,None,20,10,7,21)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "\n",
    "cv2.imshow(\"Denoised Image\", result)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Detection des visages avec la méthode de Viola et Jones\n",
    "\n",
    "Pour une image données, tracer un rectangle sur les visages détectés sur l'image. Cropper le visage détécté et enregistrer le dans un fichier .png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv2.imread('cv.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Detect faces\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "# # Draw rectangle around the faces\n",
    "# for (x, y, w, h) in faces:\n",
    "#     print(\"===\")\n",
    "#     cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "# # Display the output\n",
    "# cv2.imshow('img', img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    startRow = int(y)\n",
    "\n",
    "    startCol = int(x)\n",
    "\n",
    "    endRow = int(y+h)\n",
    "\n",
    "    endCol = int(x+w)\n",
    "\n",
    "    croppedImage = img[startRow:endRow, startCol:endCol]\n",
    "\n",
    "cv2.imshow('Cropped Image', croppedImage)\n",
    "\n",
    "\n",
    "cv2.imwrite(\"visage.png\",croppedImage)\n",
    "\n",
    "\n",
    "cv2.waitKey()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
